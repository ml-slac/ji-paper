\documentclass{article}
\usepackage{float}
\usepackage{jheppub}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{subfig}
\usepackage{natbib}
\bibliographystyle{JHEP-2}
\usepackage[utf8]{inputenc}

\title{Jet-Images -- Deep Learning Edition}
\author{Luke de Oliveira,${}^a$}
\author{Michael Kagan,${}^{b}$}
\author{Lester Mackey,${}^c$}
\author{Benjamin Nachman,${}^{b}$ and}
\author{Ariel Schwartzman${}^b$}

\affiliation{$^{a}$ Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA 94305, USA}

\affiliation{$^{b}$SLAC National Accelerator Laboratory, Stanford University, 2575 Sand Hill Rd, Menlo Park,
  CA 94025, U.S.A.}

\affiliation{$^{a}$Department of Statistics, Stanford University, Stanford, CA 94305, USA}

\emailAdd{lukedeo@stanford.edu, mkatan@cern.ch, lmackey@stanford.edu, bnachman@cern.ch, sch@slac.stanford.edu}

\abstract{Building on the notion of a particle physics detector as a camera and the collimated streams of high energy particles it measures as an image, we investigate the potential of machine learning techniques based on deep learning architectures.  Modern deep learning algorithms trained on {\it jet images} can out-perform standard physically-motivated feature driven approaches to jet tagging.  We develop techniques for visualizing where these features are learned by the network and what additional information is used to improve performance. This feedback loop between physically-motivated feature driven tools and supervised learning algorithms is general and can be used to significantly increase the sensitivity to discover new particles and new forces.}

\begin{document}

\maketitle

\section{Introduction}
Jets, or collimated sprays of particles resulting from the production of high energy quarks, provide a unique handle to search for signs of new physics at Large Hadron Collider (LHC).  Specifically, new heavy particles are predicted by a wealth of theories to decay to Standard Model (SM) particles, such as $W^{\pm}$, $Z$, and Higgs bosons, or top quarks, and in doing so impart such SM particles large amounts of energy, or boost.  This boost leads to the collimation of the SM particle's decay products, resulting in the formation of boosted heavy particle jets when the SM particle decays to quarks.   Boosted jets have a rich internal substructure which is unlike that of the typical jet backgrounds produced from vanilla Quantum Chromo Dynamic (QCD) interactions.  The identification of the underlying particle which produced a boosted jet, or jet tagging, is a fundamental challenge to searching for signs of new physics at the LHC.  There is a wealth of literature addressing the topic of jet tagging by designing physics-inspired features to exploit the jet substructure~\cite{stuff}.  However, in this paper we address the challenge of jet tagging though the use of Machine Learning (ML) and Computer Vision (CV) techniques combined with low-level information, rather than using physics inspired features.  In doing so, we not only improve discrimination power, but also gain new and deep insight into the underlying physical processes that provide discrimination power by extracting the information learned by such ML algorithms. 

The analysis presented here is an extension of the jet-images approach, first studied in~\cite{JetImages} and then studied with similar approaches by~\cite{Others}, whereby jets are represented as images with the energy depositions of the particles within the jet serving as the pixel intensities.  When first introduced, jet-image preprocessing techniques, based on the underlying physics symmetries of the jets, were combined with linear Fisher discriminant analysis (FDA) to perform jet tagging and to study the learned discrimination information.  Here, we make use of modern deep neural networks (DNN) architectures, which have been found to outperform competing algorithms in CV tasks similar to jet-tagging with jet-images.  While such DNN's are significantly more complex than FDA, they also provide the capability to learn rich high-level representations of jet-images and to greatly enhance discrimination.  By developing techniques to access this rich information, we can explore and understand what has been learned by the DNN's and subsequently use this to improve our understanding the physics governing jet substructure.  We also re-examine the jet pre-processing techniques, to specifically analyze the impact of the pre-processing on the physical information contained within the jet.

Since it's first usage by it's current name~\cite{hinton06}, Deep Learning has taken on many forms and seen success in a variety of fields that have traditionally utilized human-engineered features to create classifiers and apply out-of-the-box machine learning algorithms. In particular, the field of Computer Vision has changed drastically. Since the 2012 ILSVRC winning entry by Alex Krizhevsky and the University of Toronto group ~\cite{alexnet}, Deep Learning -- in particular Convolutional Neural Networks -- have taken over vision-based machine learning, consistently showing human and recently super-human levels performance on key baseline datasets. The increasingly widespread availability of GPUs and associated numerical frameworks has made the time intensive estimation procedures associated with deep neural networks more feasible, and has allowed the size of models for image tasks to grow exponentially. For example, the Google team's contribution to ILSVRC 2014 -- the GoogLeNet~\cite{googlenet} -- consisted of 22 layers of convolutional black boxes called ``Inception Units'', and set the benchmarks both for accuracy and speed of a model on such a large scale. 

As it relates to our work, we investigate several deep network architectures, though not as large as some described above, and focus on  understanding what information and higher level representations a fully connected and a convolutional neural network will learn in the context of High Energy Physics. We let our knowledge of physics guide our investigations into visualization, understanding, and demystification of deep representations for physics. We shed light inside the black-box of deep learning in the context of object identification in HEP.

This paper is organized as follows:  The details of the simulated data sets and the definition of jet-images are described in Section~\ref{sec:simulation}.    The pre-processing techniques, included new insights into the relationship with underlying physics information, is discussed in Section~\ref{sec:preprocess}.  We then introduce the deep neural network architectures that we us in Section~\ref{sec:arch}.  The discrimination performance and the exploration of the information learned by the DNN's is presented in Section~\ref{sec:studies}.




%With the increased energy of the LHC\cite{LHC}, and the prospects for future higher energy colliders on the horizon, the possibility of finding new high mass particles is of paramount importance.  However, when such TeV scale particles decay to Standard Model (SM) particles, such as top $W^{\pm}$, $Z$, and Higgs bosons,  or top quarks,  they impart large amounts energy, or boost to the SM particles. 

%The fundamental challenge at the energy frontier of particle physics is identifying subtle signals beneath enormous backgrounds. A monumental triumph was the recent discovery of the Higgs boson - a particle that is produced one in every $10^{10}$ collisions at the Large Hadron Collider (LHC). Machine learning techniques have played a key role in all aspects of this search.  At the most basic level, charged particle tracks are reconstructed using pattern recognition techniques, higher level objects, blah blah. 
%
%Techniques built on physically motivated features have succesfully probed the highest energies and smallest scales ever achieved in terestrial experiments.  At the same time, there have been significant gains 
%
%The high particle multiplicity final states of hadron collider events 
%Something like ``we have figured out many cool variables" "machine learning can find variables"  "lets use one to inform/improve the other!''
%
%Places where ML is used in HEP: TMVA~\cite{Hocker:2007ht}
%
%b-tagging: MV1 (ATLAS) and CSV (CMS)
%tau-tagging
%NP searches
%rare SM measurements (e.g. single top)
%Higgs
%
%Jet Images paper: http://arxiv.org/abs/1407.5675
%
%
%Let's keep a running document with all pub-ready plots in here.

\input{sections/simulation}

%\input{sections/fom}

%\input{sections/dl}

\input{sections/architecture}

\input{sections/studies}

\input{sections/conclusion}

\input{sections/acknowledgements}



\clearpage
\newpage

% \nocite{*}
 \bibliography{myrefs}





\end{document}
