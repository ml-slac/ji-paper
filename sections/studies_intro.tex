%%%%%%%%%%%
%%%    studies intro
%%%%%%%%%%%

In this section, we examine the performance of the MaxOut and Convolution deep neural networks, described in Section~\ref{sec:arch}, in classifying $W^\pm \to q q^\prime$ from QCD jets.  As one of our primary goals is to understand  what these NN's can learn about jet topology for discrimination, we focus on a restricted phase space of the mass and transverse momentum of the jets.  In particular, we restrict our studies to $250$ GeV $\leq p_T \leq 300$ GeV, and confine ourselves to a $65$ GeV $\leq m \leq 95$ GeV mass window, wholly containing the peak of the $W$.   We then construct a scaffolded and multi-approach series of methodologies for understanding, visualizing, and validating neural networks within HEP.

The primary figure of merit used to compare the performance of different classifiers is the Receiver Operating Characteristic (ROC) curve.  The ROC curves allow us to examine the entire spectrum of trade-off between Type-I and Type-II errors, as many applications of such classifiers will choose different points along the trade-off curve.   Since the classifier output distributions are not necessarily monotonic in the signal-to-background ratio, for each classifier we compute the  signal-to-background likelihood ratio\footnote{DO WE WANT TO EXPLAIN HOW LIKELIHOOD RATIOS WERE COMPUTED?}.  The ROC curves are computed by applying a threshold to the classifier output likelihood ratio, and plotting the inverse of the fraction of background jet passing the threshold (the background rejection) versus the fraction of signal events passing the threshold (the signal efficiency).  We say that an classifier is \emph{strictly} more performant if the ROC curve is above a baseline for all efficiencies.  It should be noted that any weights used to modify the distributions of jets (e.g. the $p_{T}$ weighting) are also used when computing the ROC curves.

%We use a slight modification of the traditional ROC. For any discriminating variable, let $c$ be a threshold on the likelihood ratio on that variable, and let $w$ be the vector of weights over the entire evaluation sample. We define the \emph{rejection} of such a threshold is defined as 
%$$
%    \rho(c) = \frac{1}{\text{FPR}(c, w)},
%$$
%where $\text{FPR}(c, w)$ is the weighted false positive rate for using $c$ as a threshold.
%
%We define the \emph{efficiency} of $c$ as 
%$$
%    \varepsilon(c) = \text{TPR}(c, w),
%$$
%where $\text{TPR}(c, w)$ is the weighted false positive rate for using $c$ as a threshold. We then evaluate our algorithms using the area under the line generated by $\{(\varepsilon(c), \rho(c)) : \varepsilon(c)\in [0.2, 0.8]\}$. 

For information exploration, several techniques were used:
\begin{itemize}

\item \textbf{ROC Curve Comparisons to Multi-Dimensional Likelihood Ratios:}  By combining several physics-inspired variables and computing their joint likelihood ratio, we can explore the difference between such multi-dimensional likelihood ratios and the neural networks' performance.  In doing so, we can understand if the networks learned information beyond what is contained in the multi-dimensional likelihood.  In order to more deeply inspect these comparisons, we also compute the joint likelihood ratio of the neural network output and physics-inspired variables.  if such join classifiers do not improve upon the neural network performance, then we can consider the information in the physics-inspired variable as having been learned by the neural network.  If the joint classifier shows improved performance over the neural network, then the neural network has not completely learned the information contained in the physics-inspired variable.

\item \textbf{Convolution Filters:}  For convolution neural networks, we display the weights of the 11x11 filters as images.  These filters show how discrimination information is distributed throughout patches of the jet, and give a view of the higher level representations learned by the network.  However, such filters are not always easy to interpret, and thus we also convolved each filter with a set of signal and background jet-images.  We then examine the difference between the average convolution output on the signal jet-images and the average convolution output on the background jet-images.  These difference give deeper insight to how the filters act on the jets to accentuate discriminating information.

\item \textbf{Correlations:}  We examine the 2D correlations between the neural network outputs and the physics inspired variables.  This allows to to directly see if the neural networks respond to changes in the physics inspired variables, and are thus able to learn their discrimination information.

\item \textbf{Average, Difference, and Fisher Jet-Images:}  We examine average images for signal and background, especially in windows of highly discriminating physics-inspired variables.  We further examine the difference of such averages, and the Fisher Jet computed from the jets in such windows.  This allows us to explore discriminating information contained in the jet images beyond the physics inspired variables.

\item \textbf{Neural Network Correlations per Pixel:}  We compute the linear correlations (i.e. Pearson correlation coefficient) between the neural network output and the distributions of energy in each pixel.  This allows for a visualization of how the discriminating information learned by the neural network is distributed throughout the jet.  These visualizations are an approximation to the neural network discriminator, and can be used to aid the development of new physics inspired variables (much like the Fisher Jet visualization).

\end{itemize}


The performance evaluation and information exploration techniques are examined in three settings, all of which require the aforementioned mass and transverse momentum selection.
\begin{enumerate}

\item \textbf{General Phase Space:} No alterations are made to the phase space.  This give an overview of the performance and information learned by the networks

\item  \textbf{Uniform Phase Space:}  The weights of each jet is altered such that the joint distributions of mass, $n$-subjettiness, and $p_T$ are non-discriminative.  Specifically, we derive weights such that:
\begin{equation}
  f(m, \tau_{21}, p_T| W'\rightarrow WZ) \approx f(m, \tau_{21}, p_T| QCD).
\end{equation}
Both thre reweighting and network evaluation are performed in slightly more restricted phase space requiring $\tau_{21}\in [0.2, 0.8]$. While $p_T$ is reweighted in all phase space setting, mass and $n$-subjettiness are also weighted in the setting as they are amongst the most discriminating physics-inspired variables.  This weighting ensures that mass, $n$-subjettiness, and $p_T$ do not contribute to differences between signal and background, and thus this information is essentially removed from the discrimination power of the networks.  This allows us to examine what information beyond these variables has been learned and to understand where the neural network performance improvements beyond these physics derived variables comes from.  Neural networks that are trained in the General Phase Space are applied as the discriminant under this ``flattening'' transformation. We also use the training weights inside this window and train an additional CNN. In particular, we look for increases in performance, which would indicate information learned beyond physics variables since we removed the discrimination power using this uniform weighting scheme.

\item \textbf{Highly Restricted Phase Space:} The phase space of mass, $n$-subjettiness, and $p_T$ are restricted to very small windows of size: $m\in [79, 81]$ GeV,  $p_T \in [250, 255]$ GeV, and  $\tau_21 \in [0.19, 0.21]$. No reweighting is performed, and the networks trained in the General Phase Space are used for discrimination and evaluation.  This highly restricted window is provides a different method to effectively remove any discrimination power of mass, $n$-subjettiness, and $p_T$ as there is little to no variation of the variables in these small windows for either signal or background.  Thus, any discrimination improvements of the neural networks over the physics-inspired variables would be coming from information learned beyond these variables.  While the reweighting in the Uniform  Phase Space is designed also to remove such discrimination, it produces a non-physical phase space.  Thus the Highly Restricted Phase Space allows us to be sure that the neural network performance improvements are valid and carry over to a less contrived phase space.

\end{enumerate}
By examining the performance of the neural networks in these different phase spaces, we aim to systematically remove known discriminative information from the networks' performance and thereby probe the information learned beyond what is already known by physics inspired variables.

%To begin understanding what a deep network can learn about jet topology, we choose a finite region of phase space, and standardize our comparisons. In an effort to define a standard way that physics object identification using machine learning should be conducted, we exactly define our procedure for comparisons. 

