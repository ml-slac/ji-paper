%%%%%%%%%%%
%%%    studies intro
%%%%%%%%%%%

In this section, we examine the performance of the MaxOut and Convolution deep neural networks, described in Section~\ref{sec:arch}, in classifying boosted $W^\pm \to q q^\prime$ from QCD jets.  As one of our primary goals is to understand  what these NN's can learn about jet topology for discrimination, we focus on a restricted phase space of the mass and transverse momentum of the jets.  In particular, we restrict our studies to $250$ GeV $\leq p_T \leq 300$ GeV, and confine ourselves to a $65$ GeV $\leq m \leq 95$ GeV mass window that contains the peak of the $W$.   We also perform studies in which the discrimination power of the most discriminating physics variables has been removed, either though sample weighting or highly restrictive phase space selections, which allows us to focus on information learned by the networks beyond such known physics variables.  In this way, we construct a scaffolded and multi-approach methodology for understanding, visualizing, and validating neural networks within this jet-physics study, though these approaches could be used broadly.

The primary figure of merit used to compare the performance of different classifiers is the ROC curve.  The ROC curves allow us to examine the entire spectrum of trade-off between Type-I and Type-II errors\footnote{In this context, Type-I errors refer to incorrectly rejecting the signal, while Type-II errors refer to incorrectly accepting the background.}, as many applications of such classifiers will choose different points along the trade-off curve.   Since the classifier output distributions are not necessarily monotonic in the signal-to-background ratio, for each classifier we compute the  signal-to-background likelihood ratio\footnote{Practically, this is done by binning the distribution using variable width bins such that each bin has a fixed number of background events.  This number of background events is used to regulate the approximation and we check that the results are not sensitive to this choice.}.  The ROC curves are computed by applying a threshold to the classifier output likelihood ratio, and plotting the inverse of the fraction of background jet passing the threshold (the background rejection) versus the fraction of signal events passing the threshold (the signal efficiency).  We say that a classifier is \emph{strictly} more performant if the ROC curve is above a baseline for all efficiencies.  In decision theory, this is often referred to as domination (i.e. one classifier dominates another). It should be noted that any weights used to modify the distributions of jets (e.g. the $p_{T}$ weighting described in Section~\ref{sec:simulation}) are also used when computing the ROC curves.

%We use a slight modification of the traditional ROC. For any discriminating variable, let $c$ be a threshold on the likelihood ratio on that variable, and let $w$ be the vector of weights over the entire evaluation sample. We define the \emph{rejection} of such a threshold is defined as 
%$$
%    \rho(c) = \frac{1}{\text{FPR}(c, w)},
%$$
%where $\text{FPR}(c, w)$ is the weighted false positive rate for using $c$ as a threshold.
%
%We define the \emph{efficiency} of $c$ as 
%$$
%    \varepsilon(c) = \text{TPR}(c, w),
%$$
%where $\text{TPR}(c, w)$ is the weighted false positive rate for using $c$ as a threshold. We then evaluate our algorithms using the area under the line generated by $\{(\varepsilon(c), \rho(c)) : \varepsilon(c)\in [0.2, 0.8]\}$. 

For information exploration, several techniques were used:
\begin{itemize}

\item \textbf{ROC Curve Comparisons to Multi-Dimensional Likelihood Ratios:}  By combining several physics-inspired variables and computing their joint likelihood ratio, we can explore the difference between such multi-dimensional likelihood ratios and the neural networks' performance.  In order to more deeply inspect these comparisons, we also compute the joint likelihood ratio of the neural network output and physics-inspired variables.  If such joint classifiers improve upon the neural network performance, then we can consider the information in the physics-inspired variable (conditioned on the neural network output) as having been learned by the neural network.  If the joint classifier shows improved performance over the neural network, then the neural network has not completely learned the information contained in the physics-inspired variable.

\item \textbf{Convolution Filters:}  For convolution neural networks, we display the weights of the 11x11 filters as images.  These filters show how discrimination information is distributed throughout patches of the jets and give a view of the higher level representations learned by the network.  However, such filters are not always easy to interpret, and thus we also convolve each filter with a set of signal and background jet-images.  We then examine the difference between the  convolution output on the average signal jet-images and average background jet-images.  These difference give deeper insight into how the filters act on the jets to accentuate discriminating information.

\item \textbf{Joint and Conditional Distributions:}  We examine the joint and conditional distributions of various physics inspired features and the neutral network outputs.  If the conditional distribution of the physics variable $v$ given the neural network output $O$ is not independent of the neutral network output, i.e. $P(v|O) \neq P(v)\ \forall\ O$, then we consider the network to have learned information about this physics feature.

\item \textbf{Average, Difference, and Fisher Jet-Images:}  We examine average images for signal and background and their differences, as well as the Fisher Jets.  This is particularly illuminating when we select jets with specific values of highly discriminating physics-inspired variables.  This allows us to explore discriminating information contained in the jet images beyond the physics inspired variables.

\item \textbf{Neural Network Correlations per Pixel:}  We compute the linear correlations (i.e. Pearson correlation coefficient) between the neural network output and the distributions of energy in each pixel.  This allows for a visualization of how the discriminating information learned by the neural network is distributed throughout the jet.  These visualizations are an approximation to the neural network discriminator and can be used to aid the development of new physics inspired variables (much like the Fisher Jet visualization).

\end{itemize}

\noindent The performance evaluation and information exploration techniques are examined in three settings, all of which require the aforementioned mass and transverse momentum selection.
\begin{enumerate}

\item \textbf{General Phase Space:} No alterations are made to the phase space.  This gives an overview of the performance and information learned by the networks

\item  \textbf{Uniform Phase Space:}  The weight of each jet is altered such that the joint distributions of mass, $n$-subjettiness, and $p_T$ are non-discriminative.  Specifically, we derive weights such that:
\begin{equation}
  f(m, \tau_{21}, p_T| W'\rightarrow WZ) \approx f(m, \tau_{21}, p_T| QCD).
\end{equation}
Both the weighting and network evaluation are performed in a slightly more restricted phase space requiring $\tau_{21}\in [0.2, 0.8]$. While $p_T$ is weighted in all phase space setting, mass and $n$-subjettiness are also weighted in this setting as they are amongst the most discriminating physics-inspired variables.  This weighting ensures that mass, $n$-subjettiness, and $p_T$ do not contribute to differences between signal and background, and thus this information is essentially removed from the discrimination power of the samples.  This allows us to examine what information beyond these variables has been learned and to understand where the neural network performance improvements beyond these physics derived variables comes from.  Neural networks that are trained in the General Phase Space are applied as the discriminant under this ``flattening'' transformation. We also use the training weights inside this window to train an additional convolution network. We look for increases in performance that would indicate information learned beyond the information contained in the weighted physics variables.

\item \textbf{Highly Restricted Phase Space:} The phase space of mass, $n$-subjettiness, and $p_T$ are restricted to very small windows of size: $m\in [79, 81]$ GeV,  $p_T \in [250, 255]$ GeV, and  $\tau_{21} \in [0.19, 0.21]$. No weighting (beyond the $p_{T}$ weighted described in Section~\ref{sec:simulation}) is performed, and the networks trained in the General Phase Space are used for discrimination and evaluation.  This highly restricted window provides a different method to effectively remove the discrimination power of mass, $n$-subjettiness, and $p_T$ as there is little to no variation of the variables in this phase space for either signal or background.  Thus, any discrimination improvements of the neural networks over the physics-inspired variables would be coming from information learned beyond these variables.  While the weighting in the Uniform  Phase Space is designed also to remove such discrimination, it produces a non-physical phase space.  The Highly Restricted Phase Space allows us to ensure that the neural network performance improvements are valid and transferrable to a less contrived phase space.

\end{enumerate}
By examining the performance of the neural networks in these different phase spaces, we aim to systematically remove known discriminative information from the networks' performance and thereby probe the information learned beyond what is already known by physics inspired variables.

%To begin understanding what a deep network can learn about jet topology, we choose a finite region of phase space, and standardize our comparisons. In an effort to define a standard way that physics object identification using machine learning should be conducted, we exactly define our procedure for comparisons. 

