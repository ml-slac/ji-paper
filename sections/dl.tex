\section{Deep Learning} % (fold)
\label{sec:deep_learning}

%Since it's first usage by it's current name~\cite{hinton06}, Deep Learning has taken on many forms and seen success in a variety of fields that have traditionally utilized human-engineered features to create classifiers and apply out-of-the-box machine learning algorithms. In particular, the field of Computer Vision has changed drastically. Since the 2012 ILSVRC winning entry by Alex Krizhevsky and the University of Toronto group ~\cite{alexnet}, Deep Learning -- in particular Convolutional Neural Networks -- have taken over vision-based machine learning, consistently showing human and recently super-human levels performance on key baseline datasets. The increasingly widespread availability of GPUs and associated numerical frameworks has made the time intensive estimation procedures associated with deep neural networks more feasible, and has allowed the size of models for image tasks to grow exponentially. For example, the Google team's contribution to ILSVRC 2014 -- the GoogLeNet~\cite{googlenet} -- consisted of 22 layers of convolutional black boxes called ``Inception Units'', and set the benchmarks both for accuracy and speed of a model on such a large scale. 

Automatic feature extraction and high-level learned feature representations via deep learning have led to state-of-the-art performance in Computer Vision ~\cite{vggnet}~\cite{maxout:goodfellow}~\cite{dropout:and:LRN}. As it relates to our work, do not investigate large network architectures, rather we focus on  understanding what information and higher level representations a convolutional neural network will learn in the context of High Energy Physics. We let our knowledge of physics guide our investigations into visualization, understanding, and demystification of deep representations for physics. We shed light inside the black-box of deep learning in the context of object identification in HEP.

% section deep_learning (end)
